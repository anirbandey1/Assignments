{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-o-FKEmHhSXl"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"uPAOF6aRhtOv"},"source":["# Assignment 8 -  Multimedia Lab\n","### Name - Anirban Dey\n","### Roll -  002111001108"]},{"cell_type":"markdown","metadata":{"id":"1N0caxKZiErk"},"source":["# Problem Description\n","\n","Implement Huffman algorithm, Shanon - Fano algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jJ66dJdBTZw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-9hfKjVjtSE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZYTGY1Uajt3n"},"source":["# Documentation"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from collections import defaultdict\n","from typing import List,Dict,Tuple\n","import os\n","import time\n","import heapq\n","import bitarray as ba\n","import pickle\n","import tarfile\n","import struct\n","from abc import ABC, abstractmethod\n","\n","# assert bitarray.test().wasSuccessful()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708676715358,"user":{"displayName":"Anirban Dey","userId":"01908250406120987997"},"user_tz":-330},"id":"sx9euKwJjtLV","outputId":"5e804594-11a1-405a-b86a-afaccb9f0bab"},"outputs":[],"source":["\n","class Compression(ABC):\n","  def __init__(self):\n","    pass\n","\n","  def encode(self,input_path:str,output_path:str):\n","    \"\"\"\n","      input_path : uncompressed file\n","      output_path : compressed file\n","    \"\"\"\n","    init_time = time.time()\n","\n","    prob_arr = self.generate_probability_table(file_path=input_path)\n","    huffman_code = self.generate_code(prob_arr)\n","    encoded_bitarray = ba.bitarray()\n","    # for num in data_list:\n","    #   encoded_bitarray.extend(ba.bitarray(huffman_code[num]))\n","    with open(input_path,\"rb\") as f:\n","            byte = f.read(1) # Read one byte at a time\n","            while byte :\n","                byte_num : int = ord(byte)\n","                # print(byte_num)\n","                encoded_bitarray.extend(ba.bitarray(huffman_code[byte_num]))\n","                byte = f.read(1)\n","\n","    encoded_bitarray_file_path=\"tmp_file1.bin\"\n","    dictionary_map_file_path=\"tmp_file2.bin\"\n","    tmp_file_path_list = [encoded_bitarray_file_path,dictionary_map_file_path]\n","\n","    with open(encoded_bitarray_file_path,\"wb\") as f:\n","      encoded_bitarray.tofile(f)\n","    with open(dictionary_map_file_path,\"wb\") as f:\n","      pickle.dump(huffman_code,f)\n","\n","    self.merge_files(tmp_file_path_list,output_path)\n","\n","    average_code_length = sum(len(val) for val in huffman_code.values()) / len(huffman_code.values())\n","    finish_time = time.time()\n","    original_size = os.path.getsize(input_path)\n","    compressed_size = os.path.getsize(output_path)\n","    compression_ratio = original_size / compressed_size\n","    efficiency = (1-(compressed_size/original_size))*100\n","    print(\"Time taken to compress file (in seconds) : \", finish_time - init_time )\n","    print(\"Size of input file (in bytes) : \",original_size)\n","    print(\"Size of output file (in bytes) : \",compressed_size)\n","    print(\"Average Code Length : \",average_code_length)\n","    print(\"Compression Ratio : \",compression_ratio)\n","    print(f\"Efficiency : {efficiency}%\")\n","  \n","\n","    # with tarfile.open(output_path,\"w\") as tar:\n","    #   for file_path in tmp_file_path_list:\n","    #     tar.add(file_path)\n","    #   tar.close()\n","\n","    for file_path in tmp_file_path_list:\n","      if os.path.exists(file_path) :\n","        os.unlink(file_path)\n","\n","  def decode(self,input_path:str,output_path:str):\n","    \"\"\"\n","      input_path : compressed file\n","      output_path : decompressed file\n","    \"\"\"\n","\n","    init_time = time.time()\n","\n","    # tmp_file_path_list = [encoded_biarray_file_path,dictionary_map_file_path]\n","    tmp_file_path_list = self.separate_files(merged_filename=input_path,output_dir=os.getcwd())\n","    encoded_bitarray_file_path = tmp_file_path_list[0]\n","    dictionary_map_file_path = tmp_file_path_list[1]\n","\n","    # with tarfile.open(input_path,\"r\") as tar:\n","    #   # file_names = tar.getnames()\n","    #   tar.extractall() \n","\n","    encoded_bitarray = ba.bitarray()\n","    with open(encoded_bitarray_file_path,\"rb\") as f:\n","      encoded_bitarray.fromfile(f)\n","\n","    with open(dictionary_map_file_path,\"rb\") as f:\n","      code = pickle.load(f)\n","    \n","    reverse_code:Dict[str,int] = {} # if code[x] = y  then reverse_code[y] = x\n","    for key,val in code.items():\n","      reverse_code[val] = key\n","\n","\n","    # print(\"Encoded Bitarray\")\n","    # print(encoded_bitarray)\n","    # print(\"Huffman Code\")\n","    # print(huffman_code)\n","\n","    for file_path in tmp_file_path_list:\n","      if os.path.exists(file_path) :\n","        os.unlink(file_path)\n","\n","    with open(output_path,\"wb\") as of:\n","      current_code = ba.bitarray()\n","      for bit in encoded_bitarray:\n","          current_code.append(bit)\n","          # Check if the current code is in the Huffman code dictionary\n","          if current_code.to01() in code.values():\n","              # Find the corresponding symbol for the current code using the dictionary\n","              # symbol = [k for k, v in code.items() if v == current_code.to01()][0]\n","              symbol = reverse_code[current_code.to01()]\n","             \n","              # print(symbol)\n","              # Convert the integer to a single byte and write it to the file\n","              # byte = bytes([symbol])\n","              byte = struct.pack('B',symbol)\n","              # Append the symbol to the the output file\n","              of.write(byte)\n","              # Reset the current code\n","              current_code = ba.bitarray()\n","\n","    finish_time = time.time()\n","    print(\"Time taken to decompress file (in seconds) : \",finish_time-init_time)\n","  \n","  def generate_probability_table(self,file_path:str)->List[Tuple[int,float]]:\n","\n","      freq = defaultdict(int)\n","\n","      with open(file_path,\"rb\") as f:\n","          byte = f.read(1) # Read one byte at a time\n","          while byte :\n","              byte_num : int = ord(byte)\n","              # print(byte_num)\n","              freq[byte_num] += 1\n","              byte = f.read(1)\n","\n","      freq_sum:int = 0\n","      for key,val in freq.items():\n","          freq_sum += val\n","\n","\n","      prob_arr:List[Tuple[int,float]] = []\n","      for key,val in freq.items():\n","          prob_arr.append((key,val/freq_sum))\n","      # print(\"Probability Array\")\n","      # print(prob_arr)\n","\n","      # sort freqlist by the second element in the tuple which is\n","      prob_arr.sort(key= lambda x : -x[1])\n","\n","      return prob_arr\n","  def merge_files(self,file_list:List[str], merged_filename:str):\n","      # Initialize list to store file sizes and contents\n","      merged_content = []\n","\n","      # Iterate through each file in the list\n","      for filename in file_list:\n","          # Get the size of the file\n","          file_size = os.path.getsize(filename)\n","          \n","          # Read the content of the file\n","          with open(filename, 'rb') as file:\n","              file_content = file.read()\n","          \n","          # Add size and content to the merged list\n","          merged_content.append(file_size.to_bytes(8, byteorder='big'))\n","          merged_content.append(file_content)\n","\n","      # Write the merged content to a custom merged file\n","      with open(merged_filename, 'wb') as merged_file:\n","          for item in merged_content:\n","              merged_file.write(item)\n","\n","  def separate_files(self,merged_filename:str, output_dir:str):\n","      # Read the content of the merged file\n","      with open(merged_filename, 'rb') as merged_file:\n","          merged_content = merged_file.read()\n","\n","      # Initialize list to store the names of separated files\n","      separated_files = []\n","      # Iterate through the merged content to separate files\n","      index = 0\n","      file_number = 0\n","      while index < len(merged_content):\n","          # Get size of the file\n","          file_size = int.from_bytes(merged_content[index:index+8], byteorder='big')\n","          index += 8\n","          file_number += 1\n","          \n","          # Get content of the file\n","          file_content = merged_content[index:index+file_size]\n","          index += file_size\n","          \n","          # Write content to separate file\n","          output_filename = os.path.join(output_dir, f\"tmp_file{file_number}.bin\")\n","          separated_files.append(output_filename)\n","          with open(output_filename, 'wb') as output_file:\n","              output_file.write(file_content)\n","      return separated_files\n","\n","  @abstractmethod\n","  def generate_code(self,prob_arr:List[Tuple[int,float]])->Dict[int,str]:\n","    pass\n","\n","\n","class HuffmanStandardNode():\n","      def __init__(self,num,val):\n","        self.num = num # represents the number whose frequency/probability is measured\n","        self.val = val # probability/ sum of probability\n","        self.left = None\n","        self.right = None\n","\n","      def __lt__(self,other):\n","        return self.num < other.num\n","\n","class HuffmanStandard(Compression):\n","\n","  def __init__(self):\n","    pass\n","\n","  def isLeafNode(self,node:HuffmanStandardNode):\n","    return node != None and node.left == None and node.right == None\n","\n","  def dfs(self,node:HuffmanStandardNode,cur_str:str,huffman_code:Dict[int,str]):\n","    if node == None:\n","      return\n","\n","    if self.isLeafNode(node):\n","      # print(\"Huffman Code assigned : \",node.num,cur_str)\n","      huffman_code[node.num] = cur_str\n","\n","    # print(vars(node))\n","    self.dfs(node.left,cur_str+\"0\",huffman_code)\n","    self.dfs(node.right,cur_str+\"1\",huffman_code)\n","\n","  def generate_code(self,prob_arr:List[Tuple[int,float]])->Dict[int,str]:\n","\n","    pq = []\n","    for char,prob in prob_arr:\n","      # heapq.heappush(pq,(freq,char))\n","      heapq.heappush(pq,(prob,HuffmanStandardNode(num=char,val=prob)))\n","\n","    while len(pq) > 1 :\n","      top1 = heapq.heappop(pq)\n","      top2 = heapq.heappop(pq)\n","\n","      if top1[1].val > top1[1].val:\n","        top1,top2 = top2,top1\n","\n","      # print(top1,top2)\n","      # since this is an internal node its key will -1 it does not correspond to any specific character\n","      sum_val = top1[0] + top2[0]\n","      newNode = HuffmanStandardNode(num = -1, val=sum_val)\n","      newNode.left = top1[1]\n","      newNode.right = top2[1]\n","\n","      heapq.heappush(pq,(sum_val,newNode))\n","\n","    root_of_tree = pq[0][1]\n","    # print(\"Root of tree : \",vars(root_of_tree))\n","    huffman_code = {}\n","    self.dfs(root_of_tree,\"\",huffman_code)\n","    # print(\"Huffman Code\")\n","    # print(huffman_code)\n","    return huffman_code\n","\n","\n","class ShanonFano(Compression):\n","    def __init__(self):\n","        pass\n","\n","    def dfs(self,l:int, r:int, code:str, arr:List[Tuple[int,float]],shanon_code:Dict[int,str]) -> None:\n","        # print(l,r,code,arr[l:r+1])\n","\n","        if l>r :\n","            raise ValueError(f\"Left Index {l} should be <= Right index {r}\")\n","\n","        if l == r:\n","            num:int = arr[l][0]\n","            # print(\"Shanon Code Assigned : \" ,num,code)\n","            shanon_code[num] = code\n","            return\n","\n","        prob_sum : float = 0\n","        \n","        for i in range(l,r+1):\n","            num,prob = arr[i]\n","            prob_sum += prob\n","\n","        # print(\"Probability Sum for Current Range : \",prob_sum)\n","\n","        \"\"\" \n","            In the following implmentation :\n","            sum_prob_left >= sum_prob_right\n","        \"\"\"\n","        i:int = l # i starts from l not 0\n","        cur_prob_sum:float = 0\n","        while i < r: # i cannot become r as then there would not be any element in the right subarray\n","            num,prob = arr[i]\n","            cur_prob_sum += prob\n","            if cur_prob_sum > prob_sum / 2 :\n","                break\n","            else :\n","                if i+1<r :\n","                    i+= 1\n","\n","        # print(\"Rightmost Index of Left Subarray : \",i)\n","\n","        # left subarray\n","        self.dfs(l,i,code+\"0\",arr,shanon_code)\n","        # right subarray\n","        self.dfs(i+1,r,code+\"1\",arr,shanon_code)\n","\n","    def generate_code(self,prob_arr:List[Tuple[int,float]]):\n","        shanon_code = {}\n","        self.dfs(0,len(prob_arr)-1, \"\", prob_arr,shanon_code)\n","        # print(\"ShanonCode\")\n","        # print(shanon_code)\n","        return shanon_code\n","\n","        \n","\n","\n","    "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"LiUkcIIuiLV0"},"outputs":[],"source":["# Create objects\n","hf = HuffmanStandard()\n","sf = ShanonFano()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Huffman Standard\n","Time taken to compress file (in seconds) :  0.2653207778930664\n","Size of input file (in bytes) :  263224\n","Size of output file (in bytes) :  247093\n","Average Code Length :  9.984375\n","Compression Ratio :  1.065283112026646\n","Efficiency : 6.1282405859648055%\n","Time taken to decompress file (in seconds) :  10.088044881820679\n","\n","Shanon Fano\n","Time taken to compress file (in seconds) :  0.22403383255004883\n","Size of input file (in bytes) :  263224\n","Size of output file (in bytes) :  248076\n","Average Code Length :  9.8671875\n","Compression Ratio :  1.0610619326335478\n","Efficiency : 5.754794395647811%\n","Time taken to decompress file (in seconds) :  9.405275821685791\n"]}],"source":["# Image Input\n","\n","print(\"Huffman Standard\")\n","hf.encode(input_path=\"image_input.bmp\",output_path=\"image_compressed_file_huffman_standard.bin\")\n","hf.decode(input_path=\"image_compressed_file_huffman_standard.bin\",output_path=\"image_decompressed_file_huffman_standard.bmp\")\n","\n","print(\"\\nShanon Fano\")\n","sf.encode(input_path=\"image_input.bmp\",output_path=\"image_compressed_file_shanon_fano.bin\")\n","sf.decode(input_path=\"image_compressed_file_shanon_fano.bin\",output_path=\"image_decompressed_file_shanon_fano.bmp\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Huffman Standard\n","Time taken to compress file (in seconds) :  0.07370567321777344\n","Size of input file (in bytes) :  100000\n","Size of output file (in bytes) :  26710\n","Average Code Length :  4.444444444444445\n","Compression Ratio :  3.7439161362785476\n","Efficiency : 73.29%\n","Time taken to decompress file (in seconds) :  0.16224932670593262\n","\n","Shanon Fano\n","Time taken to compress file (in seconds) :  0.06645035743713379\n","Size of input file (in bytes) :  100000\n","Size of output file (in bytes) :  28749\n","Average Code Length :  3.7777777777777777\n","Compression Ratio :  3.478381856760235\n","Efficiency : 71.251%\n","Time taken to decompress file (in seconds) :  0.11778521537780762\n"]}],"source":["# Text Input\n","\n","print(\"Huffman Standard\")\n","hf.encode(input_path=\"text_input.txt\",output_path=\"text_compressed_file_huffman_standard.bin\")\n","hf.decode(input_path=\"text_compressed_file_huffman_standard.bin\",output_path=\"text_decompressed_file_huffman_standard.txt\")\n","\n","print(\"\\nShanon Fano\")\n","sf.encode(input_path=\"text_input.txt\",output_path=\"text_compressed_file_shanon_fano.bin\")\n","sf.decode(input_path=\"text_compressed_file_shanon_fano.bin\",output_path=\"text_decompressed_file_shanon_fano.txt\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOKwop+UuoEu80WbuldqNV9","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
